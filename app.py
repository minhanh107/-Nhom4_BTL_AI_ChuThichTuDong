import torch
from PIL import Image
import gradio as gr
from transformers import BlipProcessor, BlipForConditionalGeneration
from transformers import MarianMTModel, MarianTokenizer

device = "cuda" if torch.cuda.is_available() else "cpu"

# Load mÃ´ hÃ¬nh BLIP Ä‘Ã£ fine-tune
model = BlipForConditionalGeneration.from_pretrained("blip_vi_model").to(device)
processor = BlipProcessor.from_pretrained("blip_vi_model")

# Load mÃ´ hÃ¬nh dá»‹ch Anh â†’ Viá»‡t
mt_model_name = "Helsinki-NLP/opus-mt-en-vi"
mt_tokenizer = MarianTokenizer.from_pretrained(mt_model_name)
mt_model = MarianMTModel.from_pretrained(mt_model_name).to(device)

def translate_en_to_vi(text):
    inputs = mt_tokenizer(text, return_tensors="pt", padding=True).to(device)
    translated = mt_model.generate(
        **inputs,
        num_beams=8,              # tÄƒng sá»‘ beam Ä‘á»ƒ dá»‹ch sÃ¡t nghÄ©a
        max_length=128,           # giá»›i háº¡n Ä‘á»™ dÃ i há»£p lÃ½
        repetition_penalty=1.3,   # trÃ¡nh láº·p tá»«
        length_penalty=1.0,       # cÃ¢n báº±ng cÃ¢u ngáº¯n/dÃ i
        early_stopping=True,
        no_repeat_ngram_size=2    # trÃ¡nh láº·p cá»¥m tá»«
    )
    return mt_tokenizer.decode(translated[0], skip_special_tokens=True)

def caption_image(image):
    inputs = processor(images=image, return_tensors="pt").to(device)
    output_ids = model.generate(
        **inputs,
        num_beams=5,
        max_new_tokens=30,
        repetition_penalty=1.25,
        early_stopping=True
    )
    caption_en = processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)
    caption_vi = translate_en_to_vi(caption_en)
    return caption_en, caption_vi

with gr.Blocks() as demo:
    gr.Markdown("## ğŸ–¼ï¸ á»¨NG Dá»¤NG Táº O Tá»° Äá»˜NG CHÃš THÃCH CHO HÃŒNH áº¢NH")

    # HÆ°á»›ng dáº«n thao tÃ¡c
    gr.Markdown("""
### ğŸ“Œ HÆ°á»›ng dáº«n sá»­ dá»¥ng:
1. Nháº¥n **Upload áº£nh** Ä‘á»ƒ chá»n áº£nh tá»« mÃ¡y tÃ­nh.
2. Báº¥m **Submit** Ä‘á»ƒ há»‡ thá»‘ng sinh chÃº thÃ­ch tá»± Ä‘á»™ng cho áº£nh.
3. Xem káº¿t quáº£ á»Ÿ Ã´ bÃªn pháº£i: caption tiáº¿ng Anh vÃ  báº£n dá»‹ch tiáº¿ng Viá»‡t.
4. Báº¥m **Clear** Ä‘á»ƒ xÃ³a káº¿t quáº£, báº¥m x Ä‘á»ƒ xÃ³a áº£nh hiá»‡n táº¡i vÃ  thá»­ láº¡i vá»›i áº£nh khÃ¡c.
    """)

    with gr.Row():
        with gr.Column():
            image_input = gr.Image(type="pil", label="Upload áº£nh")
            submit_btn = gr.Button("Submit", variant="primary")
            clear_btn = gr.Button("Clear", variant="stop")
        with gr.Column():
            output_en = gr.Textbox(label="Caption tiáº¿ng Anh", lines=4, interactive=False)
            output_vi = gr.Textbox(label="Caption tiáº¿ng Viá»‡t", lines=6, interactive=False)

    submit_btn.click(fn=caption_image, inputs=image_input, outputs=[output_en, output_vi])
    clear_btn.click(fn=lambda: ("", ""), inputs=None, outputs=[output_en, output_vi])

if __name__ == "__main__":
    demo.launch()
